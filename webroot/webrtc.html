<html lang="en">

<head>
  <meta charset="utf-8" http-equiv="Content-Language" content="en" />
  <meta name="description" content="WebRTC code samples">
  <meta name="viewport" content="width=device-width, user-scalable=yes, initial-scale=1, maximum-scale=1">
  <meta itemprop="description" content="Client-side WebRTC code samples">
  <meta itemprop="name" content="WebRTC code samples">
  <meta name="mobile-web-app-capable" content="yes">
  <meta id="theme-color" name="theme-color" content="#ffffff">

  <title>GStreamer webrtc camera</title>

  <link href="bootstrap.min.css" rel="stylesheet">
  <script src="bootstrap.bundle.min.js"></script>
  <!-- <script src="https://unpkg.com/vconsole@latest/dist/vconsole.min.js"></script> -->
  <style>
    * {
      margin: 0;
      padding: 0;
      box-sizing: border-box;
    }

    html,
    body {
      height: 100%;
    }

    .container {
      height: 100%;
      display: flex;
      flex-direction: column;
    }

    .visualizer {
      height: 0%;
    }


    /* Adjustments for wider screens */
    @media all and (min-width: 800px) {

      /* Don't take all the space as readability is lost when line length
     goes past a certain size */
      .container {
        width: 90%;
        max-width: 1000px;
        margin: 0 auto;
      }
    }
  </style>
  <script>
    'use strict';
    var websocketConnection;
    var webrtcPeerConnection;
    var localpc;
    var localdc;
    var localStream;
    var reportError;
    var startWatch;
    var startRecord;
    var enableTalk;
    var sendVoice;

    let isRecord = false;
    let isTalk = false;
    let isVoiceRecord = false;

    let canvas;
    let audioCtx;
    let canvasCtx;

    let hasCamera = false;
    let hasMicroPhone = false;

    // send record voice
    let lowWaterMark;
    let highWaterMark;
    const MAX_CHUNK_SIZE = 65536;
    let chunkSize;
    let mediaRecorder;
    let elapseTimer;

    // var vConsole = new window.VConsole();
    const turn_config = {
      'iceServers': [{
        urls: 'turn:192.168.1.100:3478',
        username: "test",
        credential: "test123"
      }]
    };

    const stun_config = {
      'iceServers': [{
        urls: 'stun:stunserver.stunprotocol.org:3478'
      }]
    };
    const supportedConstraints = navigator.mediaDevices.getSupportedConstraints();

    const audio_traints = {
      audio: {
        noiseSuppression: true,
        echoCancellation: true
      },
      video: false,

    };


    async function onIceCandidate(event) {
      if (event.candidate == null)
        return;

      // console.log("Sending ICE candidate out: " + JSON.stringify(event.candidate));
      await websocketConnection.send(JSON.stringify({ "type": "ice", "data": event.candidate }));
    }

    function reportError(err) {
      console.error(err);
    }

    function listCamerasAndMicrophone() {
      if (!navigator.mediaDevices || !navigator.mediaDevices.enumerateDevices) {
        console.log("enumerateDevices() not supported.");
      } else {
        // List cameras and microphones.
        navigator.mediaDevices
          .enumerateDevices()
          .then((devices) => {
            devices.forEach((device) => {
              console.log(`${device.kind}: ${device.label} \n,id = ${device.deviceId}`);
              if (device.kind === 'audioinput')
                hasMicroPhone = true;
              if (device.kind === 'videoinput')
                hasCamera = true;
            });
            console.log(`browser has camera: ${hasCamera}, has microphone: ${hasMicroPhone}`);
          })
          .catch((err) => {
            console.log(`${err.name}: ${err.message}`);
          });

      }

    }

    function toggleCanvas(show) {
      var vdom = document.getElementById('vis-dom');
      if (show === 'none') {
        vdom.style['height'] = '0%';
      } else {
        vdom.style['height'] = '10%';
      }
      vdom.style['display'] = show;
      canvas.style['display'] = show;
    }

    function stopLocalMedia() {
      if (localStream) {
        localStream.getTracks().forEach((track) => {
          track.stop();
        });
      }

      localpc.getTransceivers().forEach((transceiver) => {
        console.log("stop track.");
        transceiver.stop();
      });
      localpc.getSenders().forEach((sender) => {
        console.log("remove track.");
        localpc.removeTrack(sender);
      });
      toggleCanvas('none');
    }

    function createSender(stream) {
      toggleCanvas('block');
      console.log("stream: " + JSON.stringify(stream));
      localpc = new RTCPeerConnection(stun_config);
      if (hasCamera && hasMicroPhone) {
        localStream = stream;
        visualize(stream);
        stream.getTracks().forEach(function (track) {
          console.log("add track.");
          localpc.addTrack(track);
        });
      } else if (hasCamera) {
        console.log("just add video track");
        stream.getVideoTracks().forEach((track) => {
          localpc.addTrack(track);
        })
      } else if (hasMicroPhone) {
        localStream = stream;
        visualize(stream);
        stream.getAudioTracks().forEach((track) => {
          localpc.addTrack(track);
        })
      }

      localpc.createOffer().then(d => {
        localpc.setLocalDescription(d);
        console.log("Send offer to remote: " + d);
        websocketConnection.send(JSON.stringify({ type: "sdp", "data": d }));
      }).catch((err) => {
        console.log(" crete offer err: " + err);
      });
      localpc.oniceconnectionstatechange = e => {
        console.log("send stream state change: " + localpc.iceConnectionState);
        if (localpc.iceConnectionState == 'disconnected') {
          const pcShutdown = true;
          stopLocalMedia();
          isTalk = false;
          isVoiceRecord = false;
          enableTalk.innerHTML = isTalk ? "Video off" : "Video on";
          sendVoice.disabled = pcShutdown; //hasMicroPhone ? isTalk : true;
          sendVoice.innerHTML = isVoiceRecord ? "Send Voice" : "Start Voice";
        }
      };
      localpc.onicecandidate = onIceCandidate;
      localpc.onsignalingstatechange = (ev) => {
        switch (localpc.signalingState) {
          case "stable":
            console.log("ICE negotiation complete");
            break;
        }
      };
    }

    // buttons control
    window.onload = function () {
      listCamerasAndMicrophone();
      startWatch = document.getElementById('startWatch');
      startRecord = document.getElementById('startRecord');
      enableTalk = document.getElementById('enableTalk');
      sendVoice = document.getElementById('sendVoice');

      canvas = document.getElementById('visualizer');
      canvasCtx = canvas.getContext('2d');

      startRecord.disabled = true;
      enableTalk.disabled = true;
      sendVoice.disabled = true;
      document.querySelector('.visualizer').style['display'] = "none";

      startWatch.addEventListener('click', (event) => {
        event.preventDefault();
        console.log("start watch webrtc!!!");
        document.getElementById('loading').style['display'] = "block";
        startWatch.disabled = true;
        startWatch.classList.remove('btn-info');
        startWatch.classList.add('btn-light');
        // On firefox browser needed set media.peerconnection.use_document_iceservers = false
        // media.peerconnection.turn.disable = false

        webrtcPeerConnection = new RTCPeerConnection(stun_config);

        webrtcPeerConnection.ontrack = onAddRemoteStream;
        webrtcPeerConnection.onicecandidate = onIceCandidate;
        webrtcPeerConnection.addTransceiver('video', { 'direction': 'sendrecv' });
        webrtcPeerConnection.addTransceiver('audio', { 'direction': 'sendrecv' });
        playStream(null, null, null);

        localdc = webrtcPeerConnection.createDataChannel("web page channel", { ordered: true });

        localdc.onmessage = (event) => {
          console.log(`received: ${event.data}`);
          let msg;
          try {
            msg = JSON.parse(event.data);
          } catch (e) {
            console.log("parse json error: " + e);
            return;
          }
          if(msg.notify)
          {
            alert(msg.notify);
          }
        };

        localdc.onopen = () => {
          console.log("datachannel open");
          localdc.send("Hi, I'm browser!!!");
        };

        localdc.onclose = () => {
          console.log("datachannel close");
        };
      });

      startRecord.addEventListener('click', (event) => {
        event.preventDefault();
        console.log(startRecord.innerHTML + " on remote !!! " + isRecord);
        isRecord = !isRecord;
        startRecord.innerHTML = isRecord ? "Stop Record" : "Start Record";
        if (websocketConnection != undefined) {
          websocketConnection.send(JSON.stringify({ "type": "cmd", "cmd": "record", "arg": isRecord ? "start" : "stop" }));
        }

      });


      enableTalk.addEventListener('click', (event) => {
        console.log("enable talks now!!!");
        if (isTalk) {
          toggleCanvas('none');
          stopLocalMedia();
          websocketConnection.send(JSON.stringify({ "type": "cmd", "cmd": "talk", "arg": "stop" }));
          localStream = null;
        } else {
          // enableTalk.disabled = true;
          // To get navigator.mediaDevices, https should be enabled if not opened on localhost.
          console.log("enable talk has microphone ? " + hasMicroPhone);
          navigator.mediaDevices.getUserMedia({
            audio: hasMicroPhone ? {
              noiseSuppression: true,
              echoCancellation: true
            } : false,
            video: {
              width: { min: 800, ideal: 1280, max: 1920 },
              height: { min: 600, ideal: 720, max: 1080 },
            }
          }).then((stream) => {
            createSender(stream);
          }).catch((err) => {
            console.log("Capture media error: " + err);
          });
        }
        isTalk = !isTalk
        enableTalk.innerHTML = isTalk ? "Video off" : "Video on";
        sendVoice.disabled = hasMicroPhone ? isTalk : true;
        event.preventDefault();
      });

      function format(seconds) {
        var numhours = parseInt(Math.floor(((seconds % 31536000) % 86400) / 3600), 10);
        var numminutes = parseInt(Math.floor((((seconds % 31536000) % 86400) % 3600) / 60), 10);
        var numseconds = parseInt((((seconds % 31536000) % 86400) % 3600) % 60, 10);
        return ((numhours < 10) ? "0" + numhours : numhours)
          + ":" + ((numminutes < 10) ? "0" + numminutes : numminutes)
          + ":" + ((numseconds < 10) ? "0" + numseconds : numseconds);
      }

      function startRecordVoice(stream) {
        let chunks = [];
        console.log(" start record from stream");
        mediaRecorder = new MediaRecorder(stream);
        console.log("support audio/ogg;codecs=opus ?  " + MediaRecorder.isTypeSupported('audio/ogg;codecs=opus'));

        mediaRecorder.ondataavailable = (e) => {
          chunks.push(e.data);
        }

        mediaRecorder.onstop = (e) => {
          console.log("mediarecord on stop");
          const blob = new Blob(chunks, { 'type': 'audio/ogg; codecs=opus' });
          chunks = [];
          chunkSize = Math.min(webrtcPeerConnection.sctp.maxMessageSize, 16384);
          lowWaterMark = chunkSize;
          highWaterMark = blob.size;
          localdc.send(JSON.stringify({
            "type": "cmd", "cmd": "sendfile",
            "file": { 'type': 'audio/ogg; codecs=opus', 'size': blob.size, "name": "voice-" + performance.now() + ".ogg" }
          }));
          // localdc.binaryType = 'arraybuffer';
          localdc.bufferedAmountLowThreshold = lowWaterMark;

          var fileReader = new FileReader();
          let bufferedAmount = localdc.bufferedAmount;
          let numberSendCalls = 0;
          fileReader.onload = (e) => {
            console.log("file read blob load len : " + e.target.result.byteLength);
            while (bufferedAmount < highWaterMark) {
              numberSendCalls += 1;
              bufferedAmount += chunkSize;
              bufferedAmount = bufferedAmount > highWaterMark ? bufferedAmount + (bufferedAmount - highWaterMark) : bufferedAmount + chunkSize;
              const data = e.target.result.slice(localdc.bufferedAmount, bufferedAmount);
              localdc.send(data);
            }

          };
          fileReader.readAsArrayBuffer(blob);
        };
        mediaRecorder.start();
      }

      function makeElapseTimer(startDate) {
        var currDate = new Date();
        var diff = currDate - startDate;
        document.getElementById("elapse").innerHTML = format(diff / 1000);
      }

      function toggleElapseTimer(toStart) {
        if (toStart) {
          const nowDate = new Date();
          elapseTimer = setInterval(makeElapseTimer.bind(this, nowDate), 1000);
        } else {
          clearInterval(elapseTimer);
          document.getElementById("elapse").innerHTML = "00:00:00";
        }
        document.getElementById("elapse").style['display'] = toStart ? 'block' : 'none';
      }

      sendVoice.addEventListener('click', (event) => {
        event.preventDefault();
        if (isVoiceRecord) {
          console.log(" stop record voice.");
          mediaRecorder.stop();
          toggleElapseTimer(false);
          toggleCanvas('none');
          // send blob data;
        } else {
          console.log("start to record voice...");
          navigator.mediaDevices.getUserMedia(audio_traints).then((stream) => {
            toggleCanvas('block');
            visualize(stream);
            startRecordVoice(stream);
            sendVoice.disabled = true;
            toggleElapseTimer(true);
            setTimeout(() => {
              sendVoice.disabled = false;
            }, 2000);
          }).catch((err) => {
            console.log("Capture media error: " + err);
          });
        }

        isVoiceRecord = !isVoiceRecord;
        sendVoice.innerHTML = isVoiceRecord ? "Send Voice" : "Start Voice";
        enableTalk.disabled = isVoiceRecord;
      });
    }

    // recvonly webrtc
    async function onLocalDescription(desc) {
      console.log("Local description: " + JSON.stringify(desc));
      await webrtcPeerConnection.setLocalDescription(desc).then(function () {
        websocketConnection.send(JSON.stringify({ type: "sdp", "data": webrtcPeerConnection.localDescription }));
      }).catch(reportError);
    }


    async function onIncomingSDP(sdp) {
      console.log("Incoming SDP: " + JSON.stringify(sdp));
      if (sdp.type === "offer") {
        await webrtcPeerConnection.setRemoteDescription(sdp).catch(reportError);
        webrtcPeerConnection.createAnswer().then(onLocalDescription).catch(reportError);
      } else {
        // console.log("answser Sdp: " + sdp.sdp);
        await localpc.setRemoteDescription(sdp).catch(reportError);
      }
    }


    async function onIncomingICE(ice) {
      var candidate = new RTCIceCandidate(ice);
      if (startRecord.disabled == false && localpc) {
        console.log("answer Incoming ICE: " + JSON.stringify(ice));
        await localpc.addIceCandidate(candidate).catch(reportError);
      } else {
        await webrtcPeerConnection.addIceCandidate(candidate).catch(reportError);
      }
    }

    function recordCallBack(data) {
      alert("Recording thread is already running!!!");
      isRecord = false;
      startRecord.innerHTML = isRecord ? "Stop Record" : "Start Record";
    }

    function onAddRemoteStream(event) {
      // var el = document.createElement(event.track.kind)
      const el = document.getElementById('video0');
      el.srcObject = event.streams[0]
      el.autoplay = true
      el.controls = true

      // enable other two buttons
      changeButtonState(startRecord, false);
      changeButtonState(enableTalk, hasCamera ? false : true);
      changeButtonState(sendVoice, hasMicroPhone ? false : true);

      document.getElementById('loading').style['display'] = "none";
    }

    function changeButtonState(target, flag) {
      target.disabled = flag;
      target.classList.remove('btn-light');
      target.classList.add('btn-info');
    }

    function onServerMessage(event) {
      var msg;

      try {
        msg = JSON.parse(event.data);
      } catch (e) {
        console.log("parse json error: " + e);
        return;
      }

      if (msg.record)
        return recordCallBack(msg.record);

      switch (msg.type) {
        case "sdp": onIncomingSDP(msg.data); break;
        case "ice": onIncomingICE(msg.data); break;
        default: break;
      }
    }


    function playStream(hostname, port, path) {
      var l = window.location;
      var wsHost = (hostname != undefined) ? hostname : l.hostname;
      var wsPort = (port != undefined) ? port : l.port;
      var wsPath = (path != undefined) ? path : "ws";
      if (wsPort)
        wsPort = ":" + wsPort;
      var wsUrl = "wss://" + wsHost + wsPort + "/" + wsPath;
      websocketConnection = new WebSocket(wsUrl);
      websocketConnection.addEventListener("message", onServerMessage);
    }

    // visualizer handle
    function visualize(stream) {
      if (!audioCtx) {
        audioCtx = new AudioContext();
      }

      const source = audioCtx.createMediaStreamSource(stream);

      const analyser = audioCtx.createAnalyser();
      analyser.fftSize = 2048;
      const bufferLength = analyser.frequencyBinCount;
      const dataArray = new Uint8Array(bufferLength);

      source.connect(analyser);
      //analyser.connect(audioCtx.destination);

      draw()

      function draw() {
        const WIDTH = canvas.width
        const HEIGHT = canvas.height;
        requestAnimationFrame(draw);
        analyser.getByteTimeDomainData(dataArray);
        canvasCtx.fillStyle = 'rgb(200, 200, 200)';
        canvasCtx.fillRect(0, 0, WIDTH, HEIGHT);

        canvasCtx.lineWidth = 2;
        canvasCtx.strokeStyle = 'rgb(0, 0, 0)';

        canvasCtx.beginPath();

        let sliceWidth = WIDTH * 1.0 / bufferLength;
        let x = 0;

        for (let i = 0; i < bufferLength; i++) {
          let v = dataArray[i] / 128.0;
          let y = v * HEIGHT / 2;
          if (i === 0) {
            canvasCtx.moveTo(x, y);
          } else {
            canvasCtx.lineTo(x, y);
          }
          x += sliceWidth;
        }

        canvasCtx.lineTo(canvas.width, canvas.height / 2);
        canvasCtx.stroke();
      }
    }
  </script>
</head>

<body>
  <div>
    <h1 class="text-center">Gstreamer Webrtc Camera</h1>
    <div class="text-center " id="container">
      <video class="w-75" id="video0" playsinline autoplay></video>
      <div class="text-center mb-5" id="loading" style="display:none">
        <div class="spinner-border" role="status">
          <span class="visually-hidden">Loading...</span>
        </div>
      </div>
      <div class="visualizer w-100 d-flex justify-content-center my-2" id="vis-dom">
        <canvas class="w-75" id="visualizer"></canvas>
      </div>
      <div id="elapse"></div>
      <section class="main-controls">
        <div class="mt-3" id="buttons">
          <button type="button" class="btn btn-info" id="startWatch">Start</button>
          <button type="button" class="btn btn-light" id="startRecord">Start Record</button>
          <button type="button" class="btn btn-light" id="enableTalk">Video on</button>
          <button type="button" class="btn btn-light" id="sendVoice">Start Voice</button>
        </div>
      </section>
    </div>
  </div>
</body>

</html>